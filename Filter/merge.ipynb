{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitbaseconda7ccc1197ea424c04aa8e970980241a68",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 20)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    def merge(self):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def check_info(self, word):\n",
    "        sem_rgx = re.compile (r'[Q][A-Z]{3}')  # semantic tagset\n",
    "        syn_rgx = re.compile (r'[Y][A-Z]{3}')  # syntactic tagset\n",
    "        dom_rgx = re.compile (r'[X]{1}[ABCDEFGHIJKLMNOPQRSTUVWYZ]{3}')  # domain tagset\n",
    "        ent_rgx = re.compile (r'[X]{2}[A-Z]{2}')  # entity tagset\n",
    "        mor_rgx = re.compile (r'[A-Z]{3}')  # morph tagset\n",
    "\n",
    "        if sem_rgx.match (word):\n",
    "            return 'SenInfo'\n",
    "        elif syn_rgx.match (word):\n",
    "            return 'SynInfo'\n",
    "        elif dom_rgx.match (word):\n",
    "            return 'DomInfo'\n",
    "        elif ent_rgx.match (word):\n",
    "            return 'EntInfo'\n",
    "        elif mor_rgx.match (word):\n",
    "            return 'MorInfo'\n",
    "\n",
    "\n",
    "    def merge(self):\n",
    "\n",
    "        #들어오는 데이터를 병합할 변수\n",
    "        global merge_data\n",
    "        global cnt\n",
    "\n",
    "        #처음들어왔을 때는 병합할 필요가 없으므로 열린 파일을 merge_data에 저장\n",
    "        if (self.dataFrame_Tab.currentIndex()-1) == 0:\n",
    "            merge_data = handle_df_list[0]\n",
    "        \n",
    "        #두 번째부터는 들어오는 데이터를 data변수에 저장하고 \n",
    "        #이전에 저장해둔 merge_data와 data를 concat으로 병합한 뒤\n",
    "        #두 데이터를 sort_values로 정렬을 시켜준다.\n",
    "        else:\n",
    "            data = handle_df_list[self.dataFrame_Tab.currentIndex()-1]\n",
    "            merge_data = pd.concat([merge_data,data],ignore_index=True)\n",
    "            merge_data = merge_data.sort_values(by='Lemma')\n",
    "            merge_data = merge_data.reset_index()\n",
    "            cnt += 1\n",
    "\n",
    "        #사용자가 입력할 col_name.\n",
    "        #gui상에서 .text()로 입력받는다.\n",
    "        col_data = 'MorInfo1'\n",
    "\n",
    "        #우선시 되는 데이터 : my_data, 지워져도 되는 데이터 del_data \n",
    "        #gui상에서 .text()로 입력받는다.\n",
    "        my_data = 'ZND'\n",
    "        del_data = 'ZNZ'\n",
    "\n",
    "        \n",
    "        #파일들을 1개 이상 입력 받으면 실행된\n",
    "        if cnt != 0:\n",
    "            #중복 단어들을 저장하는 리스트\n",
    "            reduplication = []\n",
    "            #i는 처음부터 끝에서 두번째에 있는 단어들까지 돌아가고\n",
    "            #j는 i번째에 있는 단어 바로 다음 단어랑 비교를 한다.\n",
    "            #왜냐하면 정렬이 되어있는 상태기 때문에 바로 전 후의 단어들을 비교해서\n",
    "            #앞글자가 다르면 패스를 해서 시간을 단축시키기 위함이다.\n",
    "            for i in range(0,len(merge_data)-1):\n",
    "                for j in range(i+1, i+cnt+1):\n",
    "                    #first에는 i번째 단어를 음절별로 나누어서 저장하고\n",
    "                    #second에는 j번째(i다음 단어)를 음절로 나누어서 저장한다.\n",
    "                    first = Divide(merge_data.loc[i,'Lemma'])\n",
    "                    second = Divide(merge_data.loc[j,'Lemma'])\n",
    "\n",
    "                    #저장한 단어들의 앞글자가 다르면 i를 1증가시켜 다음 단어로 넘어간다.\n",
    "                    if first[0] != second[0]:\n",
    "                        break\n",
    "                    \n",
    "                    #만약 단어의 앞글자가 같다면 아래 코드를 실행한다.\n",
    "                    elif first[0] == second[0]:\n",
    "                        #앞글자는 같지만 단어가 다르면 for문을 종료한다.\n",
    "                        if first != second:\n",
    "                            break\n",
    "                        \n",
    "                        #앞글자가 같고 단어까지 같으면 입력 받은 mydata가 i번째에 있는지 아님 j(i+1)번째 있는지 확인한다.\n",
    "                        elif first == second:\n",
    "                            if my_data in merge_data.loc[i,col_data] and my_data in merge_data.loc[j,col_data]:\n",
    "                                pass\n",
    "                            elif my_data in merge_data.loc[i,col_data] and del_data in merge_data.loc[j,col_data]:\n",
    "                                #reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                                #reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "\n",
    "                                # stem_data에는 i번째 단어 정보를 리스트형태로 저장하고\n",
    "                                # follow_data에는 j번째 (i+1)번째 단어 정보를 리스트 형태로 저장한다.\n",
    "                                # 변수 x는 follow_data를 돌면서 follow_data요소가 stem_data에 정보가 없으면 \n",
    "                                # 그 정보들 check_info()함수에 넘겨서 정보를 col에 저장해준다(ex. MorInfo)\n",
    "                                # y는 merge_data의 colum 정보들을 돌면서\n",
    "                                # check_info로 입력받은 정보가 들어있는 column이 처음으로 빈칸이 나오는 장소에\n",
    "                                # stem_data에 들어있지 않은 정보(follow_data)를 merge_data에 넣어준다.\n",
    "                                stem_data1 = merge_data.iloc[i].values.tolist()\n",
    "                                follow_data1 = merge_data.iloc[j].values.tolist()\n",
    "                                for x in range(4, len(follow_data1)-1):\n",
    "                                    if follow_data1[x] not in stem_data1:\n",
    "                                        col = self.check_info(follow_data1[x])\n",
    "                                        col_nme = merge_data.columns\n",
    "                                        for y in range(4,len(col_nme)):\n",
    "                                           #print()\n",
    "                                            if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                                merge_data.loc[j, col_nme[y]] = follow_data1[x]\n",
    "                                                break\n",
    "                                \n",
    "                            elif del_data in merge_data.loc[i,col_data] and my_data in merge_data.loc[j,col_data]:\n",
    "                                #reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                                #reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "                                stem_data2 = merge_data.iloc[j].values.tolist()\n",
    "                                follow_data2 = merge_data.iloc[i].values.tolist()\n",
    "                                for x in range(4, len(follow_data2)-1):\n",
    "                                    if follow_data2[x] not in stem_data2:\n",
    "                                        col = self.check_info(follow_data2[x])\n",
    "                                        col_nme = merge_data.columns\n",
    "                                        for y in range(4,len(col_nme)):\n",
    "                                           #print()\n",
    "                                            if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                                merge_data.loc[j, col_nme[y]] = follow_data2[x]\n",
    "                                                break\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}