{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_info(self, word):\n",
    "        sem_rgx = re.compile (r'[Q][A-Z]{3}')  # semantic tagset\n",
    "        syn_rgx = re.compile (r'[Y][A-Z]{3}')  # syntactic tagset\n",
    "        dom_rgx = re.compile (r'[X]{1}[ABCDEFGHIJKLMNOPQRSTUVWYZ]{3}')  # domain tagset\n",
    "        ent_rgx = re.compile (r'[X]{2}[A-Z]{2}')  # entity tagset\n",
    "        mor_rgx = re.compile (r'[A-Z]{3}')  # morph tagset\n",
    "\n",
    "        if sem_rgx.match (word):\n",
    "            return 'SenInfo'\n",
    "        elif syn_rgx.match (word):\n",
    "            return 'SynInfo'\n",
    "        elif dom_rgx.match (word):\n",
    "            return 'DomInfo'\n",
    "        elif ent_rgx.match (word):\n",
    "            return 'EntInfo'\n",
    "        elif mor_rgx.match (word):\n",
    "            return 'MorInfo'\n",
    "\n",
    "\n",
    "    def merge(self):\n",
    "\n",
    "        #들어오는 데이터를 병합할 변수\n",
    "        global merge_data\n",
    "        global cnt\n",
    "\n",
    "        #처음들어왔을 때는 병합할 필요가 없으므로 열린 파일을 merge_data에 저장\n",
    "        if (self.dataFrame_Tab.currentIndex()-1) == 0:\n",
    "            merge_data = handle_df_list[0]\n",
    "        \n",
    "        #두 번째부터는 들어오는 데이터를 data변수에 저장하고 \n",
    "        #이전에 저장해둔 merge_data와 data를 concat으로 병합한 뒤\n",
    "        #두 데이터를 sort_values로 정렬을 시켜준다.\n",
    "        else:\n",
    "            data = handle_df_list[self.dataFrame_Tab.currentIndex()-1]\n",
    "            merge_data = pd.concat([merge_data,data],ignore_index=True)\n",
    "            merge_data = merge_data.sort_values(by='Lemma')\n",
    "            merge_data = merge_data.reset_index()\n",
    "            cnt += 1\n",
    "\n",
    "        #사용자가 입력할 col_name.\n",
    "        #gui상에서 .text()로 입력받는다.\n",
    "        col_data = 'MorInfo1'\n",
    "\n",
    "        #우선시 되는 데이터 : my_data, 지워져도 되는 데이터 del_data \n",
    "        #gui상에서 .text()로 입력받는다.\n",
    "        my_data = 'ZND'\n",
    "        del_data = 'ZNZ'\n",
    "\n",
    "        \n",
    "        #파일들을 1개 이상 입력 받으면 실행된\n",
    "        if cnt != 0:\n",
    "            #중복 단어들을 저장하는 리스트\n",
    "            reduplication = []\n",
    "            #i는 처음부터 끝에서 두번째에 있는 단어들까지 돌아가고\n",
    "            #j는 i번째에 있는 단어 바로 다음 단어랑 비교를 한다.\n",
    "            #왜냐하면 정렬이 되어있는 상태기 때문에 바로 전 후의 단어들을 비교해서\n",
    "            #앞글자가 다르면 패스를 해서 시간을 단축시키기 위함이다.\n",
    "            for i in range(0,len(merge_data)-1):\n",
    "                for j in range(i+1, i+cnt+1):\n",
    "                    #first에는 i번째 단어를 음절별로 나누어서 저장하고\n",
    "                    #second에는 j번째(i다음 단어)를 음절로 나누어서 저장한다.\n",
    "                    first = Divide(merge_data.loc[i,'Lemma'])\n",
    "                    second = Divide(merge_data.loc[j,'Lemma'])\n",
    "\n",
    "                    #저장한 단어들의 앞글자가 다르면 i를 1증가시켜 다음 단어로 넘어간다.\n",
    "                    if first[0] != second[0]:\n",
    "                        break\n",
    "                    \n",
    "                    #만약 단어의 앞글자가 같다면 아래 코드를 실행한다.\n",
    "                    elif first[0] == second[0]:\n",
    "                        #앞글자는 같지만 단어가 다르면 for문을 종료한다.\n",
    "                        if first != second:\n",
    "                            break\n",
    "                        \n",
    "                        #앞글자가 같고 단어까지 같으면 입력 받은 mydata가 i번째에 있는지 아님 j(i+1)번째 있는지 확인한다.\n",
    "                        elif first == second:\n",
    "                            if my_data in merge_data.loc[i,col_data] and my_data in merge_data.loc[j,col_data]:\n",
    "                                pass\n",
    "                            elif my_data in merge_data.loc[i,col_data] and del_data in merge_data.loc[j,col_data]:\n",
    "                                #reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                                #reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "\n",
    "                                # stem_data에는 i번째 단어 정보를 리스트형태로 저장하고\n",
    "                                # follow_data에는 j번째 (i+1)번째 단어 정보를 리스트 형태로 저장한다.\n",
    "                                # 변수 x는 follow_data를 돌면서 follow_data요소가 stem_data에 정보가 없으면 \n",
    "                                # 그 정보들 check_info()함수에 넘겨서 정보를 col에 저장해준다(ex. MorInfo)\n",
    "                                # y는 merge_data의 colum 정보들을 돌면서\n",
    "                                # check_info로 입력받은 정보가 들어있는 column이 처음으로 빈칸이 나오는 장소에\n",
    "                                # stem_data에 들어있지 않은 정보(follow_data)를 merge_data에 넣어준다.\n",
    "                                stem_data1 = merge_data.iloc[i].values.tolist()\n",
    "                                follow_data1 = merge_data.iloc[j].values.tolist()\n",
    "                                for x in range(4, len(follow_data1)-1):\n",
    "                                    if follow_data1[x] not in stem_data1:\n",
    "                                        col = self.check_info(follow_data1[x])\n",
    "                                        col_nme = merge_data.columns\n",
    "                                        for y in range(4,len(col_nme)):\n",
    "                                           #print()\n",
    "                                            if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                                merge_data.loc[j, col_nme[y]] = follow_data1[x]\n",
    "                                                break\n",
    "                                \n",
    "                            elif del_data in merge_data.loc[i,col_data] and my_data in merge_data.loc[j,col_data]:\n",
    "                                #reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                                #reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "                                stem_data2 = merge_data.iloc[j].values.tolist()\n",
    "                                follow_data2 = merge_data.iloc[i].values.tolist()\n",
    "                                for x in range(4, len(follow_data2)-1):\n",
    "                                    if follow_data2[x] not in stem_data2:\n",
    "                                        col = self.check_info(follow_data2[x])\n",
    "                                        col_nme = merge_data.columns\n",
    "                                        for y in range(4,len(col_nme)):\n",
    "                                           #print()\n",
    "                                            if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                                merge_data.loc[j, col_nme[y]] = follow_data2[x]\n",
    "                                                break\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def check_info(word):\n",
    "    sem_rgx = re.compile (r'[Q][A-Z]{3}')  # semantic tagset\n",
    "    syn_rgx = re.compile (r'[Y][A-Z]{3}')  # syntactic tagset\n",
    "    dom_rgx = re.compile (r'[X]{1}[ABCDEFGHIJKLMNOPQRSTUVWYZ]{3}')  # domain tagset\n",
    "    ent_rgx = re.compile (r'[X]{2}[A-Z]{2}')  # entity tagset\n",
    "    mor_rgx = re.compile (r'[A-Z]{3}')  # morph tagset\n",
    "\n",
    "    if sem_rgx.match (word):\n",
    "        return 'SenInfo'\n",
    "    elif syn_rgx.match (word):\n",
    "        return 'SynInfo'\n",
    "    elif dom_rgx.match (word):\n",
    "        return 'DomInfo'\n",
    "    elif ent_rgx.match (word):\n",
    "        return 'EntInfo'\n",
    "    elif mor_rgx.match (word):\n",
    "        return 'MorInfo'\n",
    "\n",
    "def column_name(df):\n",
    "    # 첫 행 살리기\n",
    "    first = list (df.columns)\n",
    "    if first[0] == 0:\n",
    "        pass\n",
    "    else:\n",
    "        df.loc[0] = first\n",
    "        for val in first:\n",
    "            if 'Unnamed' in val:\n",
    "                x = first.index (val)\n",
    "                first[x] = np.nan\n",
    "        df.loc[0] = first\n",
    "    df = df.fillna ('')\n",
    "    sem_rgx = re.compile (r'[Q][A-Z]{3}')  # semantic tagset\n",
    "    syn_rgx = re.compile (r'[Y][A-Z]{3}')  # syntactic tagset\n",
    "    dom_rgx = re.compile (r'[X]{1}[ABCDEFGHIJKLMNOPQRSTUVWYZ]{3}')  # domain tagset\n",
    "    ent_rgx = re.compile (r'[X]{2}[A-Z]{2}')  # entity tagset\n",
    "    mor_rgx = re.compile (r'[A-Z]{3}')  # morph tagset\n",
    "\n",
    "    # 컬럼의 총 개수를 l에 저장한다.\n",
    "    # 컬럼의 개수 만큼 lemma와 category뒤에 lemma와 category개수인 2를 뺀만큼\n",
    "    # ''를 추가해 주어 해당 컬럼 개수 만큼의 리스트 col_nme을 만들어 준다.\n",
    "    l = len (df.columns)\n",
    "    col_nme = ['Lemma', 'Category']\n",
    "    for i in range (l - 2):\n",
    "        col_nme.append ('')\n",
    "    # sem =>SemInfo 뒤에 붙을 숫자\n",
    "    # syn =>SynInfo 뒤에 붙을 숫자\n",
    "    # dom =>DomInfo 뒤에 붙을 숫자\n",
    "    # ent =>EntInfo 뒤에 붙을 숫자\n",
    "    # mor =>MorInfo 뒤에 붙을 숫자\n",
    "    sem = 1\n",
    "    syn = 1\n",
    "    dom = 1\n",
    "    ent = 1\n",
    "    mor = 1\n",
    "\n",
    "    # x를 컬럼의 개수 만큼의 숫자로 지정해 준다.\n",
    "    # col_val은 해당 df의 열을 리스트화 시켜준 것이다.\n",
    "    for x in range (0, l):\n",
    "        col_val = df.iloc[:, x].tolist ()\n",
    "        # cnt가 0이면 일치하는 값을 못 찾았다는 의미로 해석(ex 모두 빈칸인 열을 만났을 때)\n",
    "        # 밑에서 cnt == 0 일때 앞에 정보를 보고 빈칸의 정보를 수정할 때 사용한다.\n",
    "        cnt = 0\n",
    "        # k로 col_val의 리스트 요소들을 하나씩 지정해주면서\n",
    "        # k가 sem_rgx, syn_rgx, dom_rgx, ent_rgx, mor_rgx에 해당되면\n",
    "        # 컬럼에 일치하는 값이 있었다는 의미로 cnt를 1 증가시켜 주고\n",
    "        # Info뒤에 붙을 숫자를 1씩 증가시켜 주고\n",
    "        # 비효율적인 탐색을 막기 위해 바로 break시켜준다.\n",
    "        for k in col_val:\n",
    "            if sem_rgx.match (k):\n",
    "                col_nme[x] = 'SemInfo' + str (sem)\n",
    "                sem += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif syn_rgx.match (k):\n",
    "                col_nme[x] = 'SynInfo' + str (syn)\n",
    "                syn += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif dom_rgx.match (k):\n",
    "                col_nme[x] = 'DomInfo' + str (dom)\n",
    "                dom += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif ent_rgx.match (k):\n",
    "                col_nme[x] = 'EntInfo' + str (ent)\n",
    "                ent += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif mor_rgx.match (k):\n",
    "                col_nme[x] = 'MorInfo' + str (mor)\n",
    "                mor += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "        # 만약 위에서 일치하는 값을 못찾았을 때(ex 모두 빈칸인 열이었을 때)\n",
    "        # cnt는 0이므로 앞에 col_nme의 정보를 보고\n",
    "        # 해당 정보와 일치하는 정보의 Info숫자를 증가시켜준 값을 해당 리스트 위치에 저장해준다.\n",
    "        if cnt == 0:\n",
    "            if 'Sem' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'SemInfo' + str (sem)\n",
    "                sem += 1\n",
    "\n",
    "            elif 'Syn' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'SynInfo' + str (syn)\n",
    "                syn += 1\n",
    "\n",
    "            elif 'Dom' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'DomInfo' + str (dom)\n",
    "                dom += 1\n",
    "\n",
    "            elif 'Ent' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'EntInfo' + str (ent)\n",
    "                ent += 1\n",
    "\n",
    "            elif 'Mor' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'MorInfo' + str (mor)\n",
    "                mor += 1\n",
    "\n",
    "    df.columns = col_nme\n",
    "\n",
    "    return df\n",
    "\n",
    "def Divide(korean_word):\n",
    "    CHOSUNG_LIST = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    # 중성 리스트. 00 ~ 20\n",
    "    JUNGSUNG_LIST = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ',\n",
    "                     'ㅣ']\n",
    "    # 종성 리스트. 00 ~ 27 + 1(1개 없음)\n",
    "    JONGSUNG_LIST = [' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ',\n",
    "                     'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    r_lst = []\n",
    "    for w in list(korean_word.strip()):\n",
    "        ## 영어인 경우 구분해서 작성함.\n",
    "        if '가'<=w<='힣':\n",
    "            ## 588개 마다 초성이 바뀜.\n",
    "            ch1 = (ord(w) - ord('가'))//588\n",
    "            ## 중성은 총 28가지 종류\n",
    "            ch2 = ((ord(w) - ord('가')) - (588*ch1)) // 28\n",
    "            ch3 = (ord(w) - ord('가')) - (588*ch1) - 28*ch2\n",
    "            r_lst.append([CHOSUNG_LIST[ch1], JUNGSUNG_LIST[ch2], JONGSUNG_LIST[ch3]])\n",
    "        else:\n",
    "            r_lst.append([w])\n",
    "    return r_lst\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge():\n",
    "    # 들어오는 데이터를 병합할 변수\n",
    "\n",
    "    merge_data = pd.read_csv(r\"E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge1.csv\", header=None, encoding='utf-8-sig')\n",
    "    merge_data = column_name(merge_data)\n",
    "    data_files = [r'E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge2.csv', r\"E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge3.csv\"]\n",
    "    \n",
    "    data_df_list = []\n",
    "    for i in data_files:\n",
    "        temp_data = pd.read_csv(i, header=None, encoding='utf-8-sig')\n",
    "        temp_data = column_name(temp_data)\n",
    "        data_df_list.append(temp_data)\n",
    "    # 두 번째부터는 들어오는 데이터를 data변수에 저장하고\n",
    "    # 이전에 저장해둔 merge_data와 data를 concat으로 병합한 뒤\n",
    "    # 두 데이터를 sort_values로 정렬을 시켜준다.\n",
    "    for data in data_df_list:\n",
    "        merge_data = pd.concat ([merge_data, data], ignore_index=True)\n",
    "    merge_data = merge_data.sort_values (by='Lemma')\n",
    "    merge_data = merge_data.reset_index ()\n",
    "    # merge_data = merge_data.dropna(axis=0)\n",
    "\n",
    "    # 사용자가 입력할 col_name.\n",
    "    # gui상에서 .text()로 입력받는다.\n",
    "    col_data = 'MorInfo1'\n",
    "\n",
    "    # 우선시 되는 데이터 : my_data, 지워져도 되는 데이터 del_data\n",
    "    # gui상에서 .text()로 입력받는다.\n",
    "    rules = [['ZNZ','ZNW'],['ZNE','ZNW']]\n",
    "    for rule in rules:\n",
    "        my_data = rule[0]\n",
    "        del_data = rule[1]\n",
    "\n",
    "        # 중복 단어들을 저장하는 리스트\n",
    "        reduplication = []\n",
    "        # i는 처음부터 끝에서 두번째에 있는 단어들까지 돌아가고\n",
    "        # j는 i번째에 있는 단어 바로 다음 단어랑 비교를 한다.\n",
    "        # 왜냐하면 정렬이 되어있는 상태기 때문에 바로 전 후의 단어들을 비교해서\n",
    "        # 앞글자가 다르면 패스를 해서 시간을 단축시키기 위함이다.\n",
    "\n",
    "        for i in range (0, len(merge_data) - 1):\n",
    "            for j in range (i + 1, i + 2):\n",
    "                # first에는 i번째 단어를 음절별로 나누어서 저장하고\n",
    "                # second에는 j번째(i다음 단어)를 음절로 나누어서 저장한다.\n",
    "                first = merge_data.loc[i, 'Lemma']\n",
    "                second = merge_data.loc[j, 'Lemma']\n",
    "                print(first[0])\n",
    "\n",
    "                # # 저장한 단어들의 앞글자가 다르면 i를 1증가시켜 다음 단어로 넘어간다.\n",
    "                # if first[0] != second[0]:\n",
    "                #     break\n",
    "\n",
    "                # # 만약 단어의 앞글자가 같다면 아래 코드를 실행한다.\n",
    "                # elif first[0] == second[0]:\n",
    "                #     # 앞글자는 같지만 단어가 다르면 for문을 종료한다.\n",
    "                #     if first != second:\n",
    "                #         break\n",
    "\n",
    "                # 앞글자가 같고 단어까지 같으면 입력 받은 mydata가 i번째에 있는지 아님 j(i+1)번째 있는지 확인한다.\n",
    "                if first == second:\n",
    "                    if my_data in merge_data.loc[i, col_data] and my_data in merge_data.loc[j, col_data]:\n",
    "                        pass\n",
    "                    elif my_data in merge_data.loc[i, col_data] and del_data in merge_data.loc[j, col_data]:\n",
    "                        # reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                        # reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "\n",
    "                        # stem_data에는 i번째 단어 정보를 리스트형태로 저장하고\n",
    "                        # follow_data에는 j번째 (i+1)번째 단어 정보를 리스트 형태로 저장한다.\n",
    "                        # 변수 x는 follow_data를 돌면서 follow_data요소가 stem_data에 정보가 없으면\n",
    "                        # 그 정보들 check_info()함수에 넘겨서 정보를 col에 저장해준다(ex. MorInfo)\n",
    "                        # y는 merge_data의 colum 정보들을 돌면서\n",
    "                        # check_info로 입력받은 정보가 들어있는 column이 처음으로 빈칸이 나오는 장소에\n",
    "                        # stem_data에 들어있지 않은 정보(follow_data)를 merge_data에 넣어준다.\n",
    "                        stem_data1 = merge_data.iloc[i].values.tolist ()\n",
    "                        follow_data1 = merge_data.iloc[j].values.tolist ()\n",
    "                        for x in range (4, len (follow_data1) - 1):\n",
    "                            if follow_data1[x] not in stem_data1:\n",
    "                                print(follow_data1[x])\n",
    "                                col = check_info (follow_data1[x])\n",
    "                                col_nme = merge_data.columns\n",
    "                                for y in range (4, len (col_nme)):\n",
    "                                    if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                        merge_data.loc[j, col_nme[y]] = follow_data1[x]\n",
    "                                        break\n",
    "\n",
    "                    elif del_data in merge_data.loc[i, col_data] and my_data in merge_data.loc[j, col_data]:\n",
    "                        # reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                        # reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "                        stem_data2 = merge_data.iloc[j].values.tolist ()\n",
    "                        follow_data2 = merge_data.iloc[i].values.tolist ()\n",
    "                        for x in range (4, len (follow_data2) - 1):\n",
    "                            if follow_data2[x] not in stem_data2:\n",
    "                                col = check_info (follow_data2[x])\n",
    "                                col_nme = merge_data.columns\n",
    "                                for y in range (4, len (col_nme)):\n",
    "                                    if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                        merge_data.loc[j, col_nme[y]] = follow_data2[x]\n",
    "                                        break\n",
    "                else:\n",
    "                    break\n",
    "    print(merge_data)\n",
    "\n",
    "merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# 들어오는 데이터를 병합할 변수\n",
    "\n",
    "merge_data = pd.read_csv(r\"E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge1.csv\", header=None, encoding='utf-8-sig')\n",
    "merge_data = column_name(merge_data)\n",
    "data_files = [r'E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge2.csv', r\"E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge3.csv\"]\n",
    "\n",
    "data_df_list = []\n",
    "for i in data_files:\n",
    "    temp_data = pd.read_csv(i, header=None, encoding='utf-8-sig')\n",
    "    temp_data = column_name(temp_data)\n",
    "    data_df_list.append(temp_data)\n",
    "# 두 번째부터는 들어오는 데이터를 data변수에 저장하고\n",
    "# 이전에 저장해둔 merge_data와 data를 concat으로 병합한 뒤\n",
    "# 두 데이터를 sort_values로 정렬을 시켜준다.\n",
    "for data in data_df_list:\n",
    "    merge_data = pd.concat ([merge_data, data], ignore_index=True)\n",
    "merge_data = merge_data.sort_values (by='Lemma')\n",
    "merge_data = merge_data.reset_index ()\n",
    "merge_data = merge_data.fillna('')\n",
    "del merge_data['index']\n",
    "\n",
    "# 우선시 되는 데이터 : my_data, 지워져도 되는 데이터 del_data\n",
    "# gui상에서 .text()로 입력받는다.\n",
    "rules = [['ZNZ','ZNW'],['ZNE','ZNW']]\n",
    "for rule in rules:\n",
    "    my_data = rule[0]\n",
    "    del_data = rule[1]\n",
    "\n",
    "    # 중복 단어들을 저장하는 리스트\n",
    "    reduplication = []\n",
    "    # i는 처음부터 끝에서 두번째에 있는 단어들까지 돌아가고\n",
    "    # j는 i번째에 있는 단어 바로 다음 단어랑 비교를 한다.\n",
    "    # 왜냐하면 정렬이 되어있는 상태기 때문에 바로 전 후의 단어들을 비교해서\n",
    "    # 앞글자가 다르면 패스를 해서 시간을 단축시키기 위함이다.\n",
    "\n",
    "    for i in range (0, len(merge_data) - 1):\n",
    "        for j in range (i + 1, i + 2):\n",
    "            # first에는 i번째 단어를 음절별로 나누어서 저장하고\n",
    "            # second에는 j번째(i다음 단어)를 음절로 나누어서 저장한다.\n",
    "            first = merge_data.loc[i, 'Lemma']\n",
    "            second = merge_data.loc[j, 'Lemma']\n",
    "\n",
    "            if first == second:\n",
    "                if my_data in merge_data.loc[i, 'MorInfo1'] and my_data in merge_data.loc[j, 'MorInfo1']:\n",
    "                        pass\n",
    "                if my_data in merge_data.loc[i, 'MorInfo1'] and del_data in merge_data.loc[j, 'MorInfo1']:\n",
    "                        # reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                        # reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "\n",
    "                        # stem_data에는 i번째 단어 정보를 리스트형태로 저장하고\n",
    "                        # follow_data에는 j번째 (i+1)번째 단어 정보를 리스트 형태로 저장한다.\n",
    "                        # 변수 x는 follow_data를 돌면서 follow_data요소가 stem_data에 정보가 없으면\n",
    "                        # 그 정보들 check_info()함수에 넘겨서 정보를 col에 저장해준다(ex. MorInfo)\n",
    "                        # y는 merge_data의 colum 정보들을 돌면서\n",
    "                        # check_info로 입력받은 정보가 들어있는 column이 처음으로 빈칸이 나오는 장소에\n",
    "                        # stem_data에 들어있지 않은 정보(follow_data)를 merge_data에 넣어준다.\n",
    "                        stem_data1 = merge_data.iloc[i].values.tolist ()\n",
    "                        follow_data1 = merge_data.iloc[j].values.tolist ()\n",
    "                        for x in range (4, len (follow_data1) - 1):\n",
    "                            if follow_data1[x] not in stem_data1:\n",
    "                                print(follow_data1[x])\n",
    "                                col = check_info (follow_data1[x])\n",
    "                                col_nme = merge_data.columns\n",
    "                                for y in range (4, len (col_nme)):\n",
    "                                    if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                        merge_data.loc[j, col_nme[y]] = follow_data1[x]\n",
    "                                        break\n",
    "\n",
    "                elif del_data in merge_data.loc[i, 'MorInfo1'] and my_data in merge_data.loc[j, 'MorInfo1']:\n",
    "                        # reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                        # reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "                        stem_data2 = merge_data.iloc[j].values.tolist ()\n",
    "                        follow_data2 = merge_data.iloc[i].values.tolist ()\n",
    "                        for x in range (4, len (follow_data2) - 1):\n",
    "                            if follow_data2[x] not in stem_data2:\n",
    "                                col = check_info (follow_data2[x])\n",
    "                                col_nme = merge_data.columns\n",
    "                                for y in range (4, len (col_nme)):\n",
    "                                    if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                        merge_data.loc[j, col_nme[y]] = follow_data2[x]\n",
    "                                        break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "print(merge_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge():\n",
    "    # 들어오는 데이터를 병합할 변수\n",
    "\n",
    "   # 들어오는 데이터를 병합할 변수\n",
    "\n",
    "    merge_data = pd.read_csv(r\"E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge1.csv\", header=None, encoding='utf-8-sig')\n",
    "    merge_data = column_name(merge_data)\n",
    "    data_files = [r'E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge2.csv', r\"E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge3.csv\"]\n",
    "\n",
    "    for i in data_files:\n",
    "        temp_data = pd.read_csv(i, header=None, encoding='utf-8-sig')\n",
    "        temp_data = column_name(temp_data)\n",
    "        data_df_list.append(temp_data)\n",
    "    # 두 번째부터는 들어오는 데이터를 data변수에 저장하고\n",
    "    # 이전에 저장해둔 merge_data와 data를 concat으로 병합한 뒤\n",
    "    # 두 데이터를 sort_values로 정렬을 시켜준다.\n",
    "    for data in data_df_list:\n",
    "        merge_data = pd.concat ([merge_data, data], ignore_index=True)\n",
    "    merge_data = merge_data.sort_values (by='Lemma')\n",
    "    merge_data = merge_data.reset_index ()\n",
    "    merge_data = merge_data.fillna('')\n",
    "    del merge_data['index']\n",
    "    cnt = 1\n",
    "    # 사용자가 입력할 col_name.\n",
    "    # gui상에서 .text()로 입력받는다.\n",
    "    col_data = 'MorInfo1'\n",
    "\n",
    "    # 우선시 되는 데이터 : my_data, 지워져도 되는 데이터 del_data\n",
    "    # gui상에서 .text()로 입력받는다.\n",
    "    rules = [['ZNZ','ZNW'],['ZNE','ZNW']]\n",
    "    for rule in rules:\n",
    "        my_data = rule[0]\n",
    "        del_data = rule[1]\n",
    "        for i in range (0, len(merge_data) - 1):\n",
    "            for j in range (i + 1, i + cnt + 1):\n",
    "                # first에는 i번째 단어를 음절별로 나누어서 저장하고\n",
    "                # second에는 j번째(i다음 단어)를 음절로 나누어서 저장한다.\n",
    "                first = Divide (merge_data.loc[i, 'Lemma'])\n",
    "                second = Divide (merge_data.loc[j, 'Lemma'])\n",
    "                if first[0] != second[0]:\n",
    "                    break\n",
    "                    # 만약 단어의 앞글자가 같다면 아래 코드를 실행한다.\n",
    "                else:\n",
    "                    # 앞글자는 같지만 단어가 다르면 for문을 종료한다.\n",
    "                    if first != second:\n",
    "                        break\n",
    "\n",
    "                    # 앞글자가 같고 단어까지 같으면 입력 받은 mydata가 i번째에 있는지 아님 j(i+1)번째 있는지 확인한다.\n",
    "                    else:\n",
    "                        if my_data == merge_data.loc[i, col_data] and del_data == merge_data.loc[j, col_data]:\n",
    "                            # reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                            # reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "\n",
    "                            # stem_data에는 i번째 단어 정보를 리스트형태로 저장하고\n",
    "                            # follow_data에는 j번째 (i+1)번째 단어 정보를 리스트 형태로 저장한다.\n",
    "                            # 변수 x는 follow_data를 돌면서 follow_data요소가 stem_data에 정보가 없으면\n",
    "                            # 그 정보들 check_info()함수에 넘겨서 정보를 col에 저장해준다(ex. MorInfo)\n",
    "                            # y는 merge_data의 colum 정보들을 돌면서\n",
    "                            # check_info로 입력받은 정보가 들어있는 column이 처음으로 빈칸이 나오는 장소에\n",
    "                            # stem_data에 들어있지 않은 정보(follow_data)를 merge_data에 넣어준다.\n",
    "                            stem_data1 = merge_data.iloc[i].values.tolist ()\n",
    "                            follow_data1 = merge_data.iloc[j].values.tolist ()\n",
    "                            for x in range (4, len (follow_data1) - 1):\n",
    "                                if follow_data1[x] not in stem_data1:\n",
    "                                    col = check_info (follow_data1[x])\n",
    "                                    col_nme = merge_data.columns\n",
    "                                    for y in range (4, len (col_nme)):\n",
    "                                        if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                            merge_data.loc[j, col_nme[y]] = follow_data1[x]\n",
    "                                            break\n",
    "\n",
    "                        elif my_data == merge_data.loc[i, col_data] and del_data == merge_data.loc[j, col_data]:\n",
    "                            # reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                            # reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "                            stem_data2 = merge_data.iloc[j].values.tolist ()\n",
    "                            follow_data2 = merge_data.iloc[i].values.tolist ()\n",
    "                            for x in range (4, len (follow_data2) - 1):\n",
    "                                if follow_data2[x] not in stem_data2:\n",
    "                                    col = check_info (follow_data2[x])\n",
    "                                    col_nme = merge_data.columns\n",
    "                                    for y in range (4, len (col_nme)):\n",
    "                                        if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                            merge_data.loc[j, col_nme[y]] = follow_data2[x]\n",
    "                                            break\n",
    "\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "                    \n",
    "        print(merge_data)\n",
    "        \n",
    "merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def column_name(df):\n",
    "    # 첫 행 살리기\n",
    "    first = list (df.columns)\n",
    "    if first[0] == 0:\n",
    "        pass\n",
    "    else:\n",
    "        df.loc[0] = first\n",
    "        for val in first:\n",
    "            if 'Unnamed' in val:\n",
    "                x = first.index (val)\n",
    "                first[x] = np.nan\n",
    "        df.loc[0] = first\n",
    "    df = df.fillna ('')\n",
    "    sem_rgx = re.compile (r'[Q][A-Z]{3}')  # semantic tagset\n",
    "    syn_rgx = re.compile (r'[Y][A-Z]{3}')  # syntactic tagset\n",
    "    dom_rgx = re.compile (r'[X]{1}[ABCDEFGHIJKLMNOPQRSTUVWYZ]{3}')  # domain tagset\n",
    "    ent_rgx = re.compile (r'[X]{2}[A-Z]{2}')  # entity tagset\n",
    "    mor_rgx = re.compile (r'[A-Z]{3}')  # morph tagset\n",
    "\n",
    "    # 컬럼의 총 개수를 l에 저장한다.\n",
    "    # 컬럼의 개수 만큼 lemma와 category뒤에 lemma와 category개수인 2를 뺀만큼\n",
    "    # ''를 추가해 주어 해당 컬럼 개수 만큼의 리스트 col_nme을 만들어 준다.\n",
    "    l = len (df.columns)\n",
    "    col_nme = ['Lemma', 'Category']\n",
    "    for i in range (l - 2):\n",
    "        col_nme.append ('')\n",
    "    # sem =>SemInfo 뒤에 붙을 숫자\n",
    "    # syn =>SynInfo 뒤에 붙을 숫자\n",
    "    # dom =>DomInfo 뒤에 붙을 숫자\n",
    "    # ent =>EntInfo 뒤에 붙을 숫자\n",
    "    # mor =>MorInfo 뒤에 붙을 숫자\n",
    "    sem = 1\n",
    "    syn = 1\n",
    "    dom = 1\n",
    "    ent = 1\n",
    "    mor = 1\n",
    "\n",
    "    # x를 컬럼의 개수 만큼의 숫자로 지정해 준다.\n",
    "    # col_val은 해당 df의 열을 리스트화 시켜준 것이다.\n",
    "    for x in range (0, l):\n",
    "        col_val = df.iloc[:, x].tolist ()\n",
    "        # cnt가 0이면 일치하는 값을 못 찾았다는 의미로 해석(ex 모두 빈칸인 열을 만났을 때)\n",
    "        # 밑에서 cnt == 0 일때 앞에 정보를 보고 빈칸의 정보를 수정할 때 사용한다.\n",
    "        cnt = 0\n",
    "        # k로 col_val의 리스트 요소들을 하나씩 지정해주면서\n",
    "        # k가 sem_rgx, syn_rgx, dom_rgx, ent_rgx, mor_rgx에 해당되면\n",
    "        # 컬럼에 일치하는 값이 있었다는 의미로 cnt를 1 증가시켜 주고\n",
    "        # Info뒤에 붙을 숫자를 1씩 증가시켜 주고\n",
    "        # 비효율적인 탐색을 막기 위해 바로 break시켜준다.\n",
    "        for k in col_val:\n",
    "            if sem_rgx.match (k):\n",
    "                col_nme[x] = 'SemInfo' + str (sem)\n",
    "                sem += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif syn_rgx.match (k):\n",
    "                col_nme[x] = 'SynInfo' + str (syn)\n",
    "                syn += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif dom_rgx.match (k):\n",
    "                col_nme[x] = 'DomInfo' + str (dom)\n",
    "                dom += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif ent_rgx.match (k):\n",
    "                col_nme[x] = 'EntInfo' + str (ent)\n",
    "                ent += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif mor_rgx.match (k):\n",
    "                col_nme[x] = 'MorInfo' + str (mor)\n",
    "                mor += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "        # 만약 위에서 일치하는 값을 못찾았을 때(ex 모두 빈칸인 열이었을 때)\n",
    "        # cnt는 0이므로 앞에 col_nme의 정보를 보고\n",
    "        # 해당 정보와 일치하는 정보의 Info숫자를 증가시켜준 값을 해당 리스트 위치에 저장해준다.\n",
    "        if cnt == 0:\n",
    "            if 'Sem' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'SemInfo' + str (sem)\n",
    "                sem += 1\n",
    "\n",
    "            elif 'Syn' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'SynInfo' + str (syn)\n",
    "                syn += 1\n",
    "\n",
    "            elif 'Dom' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'DomInfo' + str (dom)\n",
    "                dom += 1\n",
    "\n",
    "            elif 'Ent' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'EntInfo' + str (ent)\n",
    "                ent += 1\n",
    "\n",
    "            elif 'Mor' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'MorInfo' + str (mor)\n",
    "                mor += 1\n",
    "\n",
    "    df.columns = col_nme\n",
    "\n",
    "    return df\n",
    "def Divide(korean_word):\n",
    "    CHOSUNG_LIST = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    # 중성 리스트. 00 ~ 20\n",
    "    JUNGSUNG_LIST = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ',\n",
    "                     'ㅣ']\n",
    "    # 종성 리스트. 00 ~ 27 + 1(1개 없음)\n",
    "    JONGSUNG_LIST = [' ', 'ㄱ', 'ㄲ', 'ㄳ', 'ㄴ', 'ㄵ', 'ㄶ', 'ㄷ', 'ㄹ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ', 'ㄾ', 'ㄿ', 'ㅀ', 'ㅁ', 'ㅂ', 'ㅄ', 'ㅅ',\n",
    "                     'ㅆ', 'ㅇ', 'ㅈ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', 'ㅎ']\n",
    "    r_lst = []\n",
    "    for w in list(korean_word.strip()):\n",
    "        ## 영어인 경우 구분해서 작성함.\n",
    "        if '가'<=w<='힣':\n",
    "            ## 588개 마다 초성이 바뀜.\n",
    "            ch1 = (ord(w) - ord('가'))//588\n",
    "            ## 중성은 총 28가지 종류\n",
    "            ch2 = ((ord(w) - ord('가')) - (588*ch1)) // 28\n",
    "            ch3 = (ord(w) - ord('가')) - (588*ch1) - 28*ch2\n",
    "            r_lst.append([CHOSUNG_LIST[ch1], JUNGSUNG_LIST[ch2], JONGSUNG_LIST[ch3]])\n",
    "        else:\n",
    "            r_lst.append([w])\n",
    "    return r_lst\n",
    "def check_info(word):\n",
    "    sem_rgx = re.compile (r'[Q][A-Z]{3}')  # semantic tagset\n",
    "    syn_rgx = re.compile (r'[Y][A-Z]{3}')  # syntactic tagset\n",
    "    dom_rgx = re.compile (r'[X]{1}[ABCDEFGHIJKLMNOPQRSTUVWYZ]{3}')  # domain tagset\n",
    "    ent_rgx = re.compile (r'[X]{2}[A-Z]{2}')  # entity tagset\n",
    "    mor_rgx = re.compile (r'[A-Z]{3}')  # morph tagset\n",
    "\n",
    "    if sem_rgx.match (word):\n",
    "        return 'SenInfo'\n",
    "    elif syn_rgx.match (word):\n",
    "        return 'SynInfo'\n",
    "    elif dom_rgx.match (word):\n",
    "        return 'DomInfo'\n",
    "    elif ent_rgx.match (word):\n",
    "        return 'EntInfo'\n",
    "    elif mor_rgx.match (word):\n",
    "        return 'MorInfo'\n",
    "def merge():\n",
    "    # 들어오는 데이터를 병합할 변수\n",
    "\n",
    "    merge_data = pd.read_csv(r\"E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge1.csv\", header=None, encoding='utf-8-sig')\n",
    "    merge_data = column_name(merge_data)\n",
    "    data_files = [r'E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge2.csv', r'E:\\Programming\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge3.csv']\n",
    "    data_df_list = []\n",
    "    for i in data_files:\n",
    "        temp_data = pd.read_csv(i, header=None, encoding='utf-8-sig')\n",
    "        temp_data = column_name(temp_data)\n",
    "        data_df_list.append(temp_data)\n",
    "    # 두 번째부터는 들어오는 데이터를 data변수에 저장하고\n",
    "    # 이전에 저장해둔 merge_data와 data를 concat으로 병합한 뒤\n",
    "    # 두 데이터를 sort_values로 정렬을 시켜준다.\n",
    "    for data in data_df_list:\n",
    "        merge_data = pd.concat ([merge_data, data], ignore_index=True)\n",
    "    merge_data = merge_data.sort_values (by='Lemma')\n",
    "    merge_data = merge_data.reset_index ()\n",
    "    merge_data = merge_data.fillna('')\n",
    "    del merge_data['index']\n",
    "    cnt = 1\n",
    "    # 사용자가 입력할 col_name.\n",
    "    # gui상에서 .text()로 입력받는다.\n",
    "    col_data = 'MorInfo1'\n",
    "\n",
    "    # 우선시 되는 데이터 : my_data, 지워져도 되는 데이터 del_data\n",
    "    # gui상에서 .text()로 입력받는다.\n",
    "    rules = [['ZNZ','ZNW'],['ZNE','ZNW']]\n",
    "    del_row_list = []\n",
    "    for rule in rules:\n",
    "        my_data = rule[0]\n",
    "        del_data = rule[1]\n",
    "        for i in range (0, len(merge_data) - 1):\n",
    "            for j in range (i + 1, i + cnt + 1):\n",
    "                # first에는 i번째 단어를 음절별로 나누어서 저장하고\n",
    "                # second에는 j번째(i다음 단어)를 음절로 나누어서 저장한다.\n",
    "                first = Divide (merge_data.loc[i, 'Lemma'])\n",
    "                second = Divide (merge_data.loc[j, 'Lemma'])\n",
    "                if first[0] != second[0]:\n",
    "                    break\n",
    "                    # 만약 단어의 앞글자가 같다면 아래 코드를 실행한다.\n",
    "                else:\n",
    "                    # 앞글자는 같지만 단어가 다르면 for문을 종료한다.\n",
    "                    if first != second:\n",
    "                        break\n",
    "\n",
    "                    # 앞글자가 같고 단어까지 같으면 입력 받은 mydata가 i번째에 있는지 아님 j(i+1)번째 있는지 확인한다.\n",
    "                    else:\n",
    "                        if my_data == merge_data.loc[i, col_data] and del_data == merge_data.loc[j, col_data]:\n",
    "                            # reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                            # reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "\n",
    "                            # stem_data에는 i번째 단어 정보를 리스트형태로 저장하고\n",
    "                            # follow_data에는 j번째 (i+1)번째 단어 정보를 리스트 형태로 저장한다.\n",
    "                            # 변수 x는 follow_data를 돌면서 follow_data요소가 stem_data에 정보가 없으면\n",
    "                            # 그 정보들 check_info()함수에 넘겨서 정보를 col에 저장해준다(ex. MorInfo)\n",
    "                            # y는 merge_data의 colum 정보들을 돌면서\n",
    "                            # check_info로 입력받은 정보가 들어있는 column이 처음으로 빈칸이 나오는 장소에\n",
    "                            # stem_data에 들어있지 않은 정보(follow_data)를 merge_data에 넣어준다.\n",
    "                            stem_data1 = merge_data.iloc[i].values.tolist ()\n",
    "                            follow_data1 = merge_data.iloc[j].values.tolist ()\n",
    "                            for x in range (4, len (follow_data1) - 1):\n",
    "                                if follow_data1[x] not in stem_data1:\n",
    "                                    col = check_info (follow_data1[x])\n",
    "                                    col_nme = merge_data.columns\n",
    "                                    for y in range (4, len(col_nme)):\n",
    "                                        if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                            merge_data.loc[j, col_nme[y]] = follow_data1[x]\n",
    "                                            break\n",
    "                            del_row_list.append(j)\n",
    "\n",
    "                        elif my_data == merge_data.loc[i, col_data] and del_data == merge_data.loc[j, col_data]:\n",
    "                            # reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                            # reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "                            stem_data2 = merge_data.iloc[j].values.tolist ()\n",
    "                            follow_data2 = merge_data.iloc[i].values.tolist ()\n",
    "                            for x in range (4, len (follow_data2) - 1):\n",
    "                                if follow_data2[x] not in stem_data2:\n",
    "                                    col = check_info (follow_data2[x])\n",
    "                                    col_nme = merge_data.columns\n",
    "                                    for y in range (4, len (col_nme)):\n",
    "                                        if col in col_nme[y] and merge_data.loc[j, col_nme[y]] == '':\n",
    "                                            merge_data.loc[j, col_nme[y]] = follow_data2[x]\n",
    "                                            break\n",
    "                            del_row_list.append(j)\n",
    "                        else:\n",
    "                            pass\n",
    "    del_temp = []\n",
    "    for i in del_row_list:\n",
    "        del_temp.append(merge_data.iloc[i].tolist())\n",
    "    del_df = pd.DataFrame(del_temp)\n",
    "    del_df = column_name(del_df)\n",
    "    del_df.to_csv(\"res_del_merge.csv\", header=False, index=False, na_rep='', encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "    merge_data = merge_data.drop(del_row_list, 0)\n",
    "    merge_data = merge_data.reset_index()\n",
    "    del merge_data[\"index\"]\n",
    "\n",
    "    return merge_data.to_csv(\"res_merge.csv\", header=False, index=False, na_rep='', encoding='utf-8-sig')\n",
    "merge()\n",
    "print('RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_fname=([r\"E:\\Develop\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge2.csv\", r\"E:\\Develop\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge3.csv\"], 'CSV Files(*.csv)')\n",
    "\n",
    "# def merge(self):\n",
    "\n",
    "# 들어오는 데이터를 병합할 변수\n",
    "merge_data = pd.read_csv (merge_fname[0][0], header=None, encoding='utf-8-sig')\n",
    "merge_data = column_name (merge_data)\n",
    "print(\"origin\", merge_data)\n",
    "data_files = merge_fname[0][1:]\n",
    "data_df_list = []\n",
    "for i in data_files:\n",
    "    temp_data = pd.read_csv (i, header=None, encoding='utf-8-sig')\n",
    "    temp_data = column_name (temp_data)\n",
    "    data_df_list.append (temp_data)\n",
    "# 두 번째부터는 들어오는 데이터를 data변수에 저장하고\n",
    "# 이전에 저장해둔 merge_data와 data를 concat으로 병합한 뒤\n",
    "# 두 데이터를 sort_values로 정렬을 시켜준다.\n",
    "for data in data_df_list:\n",
    "    print('data\\n', data)\n",
    "    merge_data = pd.concat ([merge_data, data], ignore_index=True)\n",
    "merge_data = merge_data.sort_values (by='Lemma')\n",
    "merge_data = merge_data.reset_index ()\n",
    "merge_data = merge_data.fillna ('')\n",
    "del merge_data['index']\n",
    "print(\"merge_data\\n\", merge_data)\n",
    "cnt = 1\n",
    "\n",
    "# 우선시 되는 데이터 : my_data, 지워져도 되는 데이터 del_data\n",
    "# gui상에서 .text()로 입력받는다.\n",
    "rule_data = pd.read_csv (r\"E:\\Develop\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Rules.csv\", header=None, encoding='utf-8-sig')\n",
    "rules = []\n",
    "for rule_cnt in range (len (rule_data)):\n",
    "    rules.append (rule_data.loc[rule_cnt].to_list ())\n",
    "print(\"rules\\n\", rules)\n",
    "# 사용자가 입력할 col_name.\n",
    "# gui상에서 .text()로 입력받는다.\n",
    "col_data = 'MorInfo1'\n",
    "\n",
    "del_row_list = []\n",
    "for rule in rules:\n",
    "    my_data = rule[0]\n",
    "    del_data = rule[1]\n",
    "    for i in range (0, len (merge_data) - 1):\n",
    "        for j in range (i + 1, i + cnt + 1):\n",
    "            # first에는 i번째 단어를 음절별로 나누어서 저장하고\n",
    "            # second에는 j번째(i다음 단어)를 음절로 나누어서 저장한다.\n",
    "            first = merge_data.loc[i, 'Lemma']\n",
    "            second = merge_data.loc[j, 'Lemma']\n",
    "            first_len = len (merge_data.loc[i, 'Lemma'])\n",
    "            second_len = len (merge_data.loc[j, 'Lemma'])\n",
    "            if first_len != second_len:\n",
    "                break\n",
    "                # 만약 단어의 앞글자가 같다면 아래 코드를 실행한다.\n",
    "            else:\n",
    "                # 앞글자는 같지만 단어가 다르면 for문을 종료한다.\n",
    "                if first != second:\n",
    "                    break\n",
    "\n",
    "                # 앞글자가 같고 단어까지 같으면 입력 받은 mydata가 i번째에 있는지 아님 j(i+1)번째 있는지 확인한다.\n",
    "                else:\n",
    "                    print(\"i\", i, merge_data.loc[i, col_data])\n",
    "                    print(\"j\", j, merge_data.loc[j, col_data])\n",
    "                    if my_data == merge_data.loc[i, col_data] and del_data == merge_data.loc[j, col_data]:\n",
    "                        # reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                        # reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "\n",
    "                        # stem_data에는 i번째 단어 정보를 리스트형태로 저장하고\n",
    "                        # follow_data에는 j번째 (i+1)번째 단어 정보를 리스트 형태로 저장한다.\n",
    "                        # 변수 x는 follow_data를 돌면서 follow_data요소가 stem_data에 정보가 없으면\n",
    "                        # 그 정보들 check_info()함수에 넘겨서 정보를 col에 저장해준다(ex. MorInfo)\n",
    "                        # y는 merge_data의 colum 정보들을 돌면서\n",
    "                        # check_info로 입력받은 정보가 들어있는 column이 처음으로 빈칸이 나오는 장소에\n",
    "                        # stem_data에 들어있지 않은 정보(follow_data)를 merge_data에 넣어준다.\n",
    "                        stem_data1 = merge_data.iloc[i].values.tolist ()[2:]\n",
    "                        follow_data1 = merge_data.iloc[j].values.tolist ()[2:]\n",
    "                        print(\"s1\",stem_data1)\n",
    "                        print(\"f1\",follow_data1)\n",
    "                        for data in stem_data1:\n",
    "                            if data not in follow_data1:\n",
    "                                col = check_info (data)\n",
    "                                col_nme = merge_data.columns\n",
    "                                for mer_col in col_nme:\n",
    "                                    if col in mer_col and merge_data.loc[j, mer_col] == '':\n",
    "                                        merge_data.loc[i, mer_col] = data\n",
    "                                        break\n",
    "                        del_row_list.append (j)\n",
    "\n",
    "                    elif my_data == merge_data.loc[j, col_data] and del_data == merge_data.loc[i, col_data]:\n",
    "                        # reduplication.append(merge_data.iloc[i].values.tolist())\n",
    "                        # reduplication.append(merge_data.iloc[j].values.tolist())\n",
    "                        stem_data2 = merge_data.iloc[j].values.tolist ()[2:]\n",
    "                        follow_data2 = merge_data.iloc[i].values.tolist ()[2:]\n",
    "                        print(\"s2\",stem_data2)\n",
    "                        print(\"f2\",follow_data2)\n",
    "                        for data in stem_data2:\n",
    "                            if data not in follow_data2:\n",
    "                                col = check_info (data)\n",
    "                                #print(\"col\", col)\n",
    "                                col_nme = merge_data.columns\n",
    "                                #print(col_nme)\n",
    "                                for mer_col in col_nme:\n",
    "                                    if col in mer_col and merge_data.loc[i, mer_col] == '':\n",
    "                                        merge_data.loc[j, mer_col] = my_data\n",
    "                                        break\n",
    "                        del_row_list.append (j)\n",
    "                    else:\n",
    "                        pass\n",
    "del_temp = []\n",
    "for i in del_row_list:\n",
    "    del_temp.append (merge_data.iloc[i].tolist ())\n",
    "del_df = pd.DataFrame (del_temp)\n",
    "if len(del_df) != 0:\n",
    "    del_df = column_name (del_df)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(del_df)\n",
    "\n",
    "merge_data = merge_data.drop (del_row_list, 0)\n",
    "merge_data = merge_data.reset_index ()\n",
    "del merge_data[\"index\"]\n",
    "\n",
    "print(merge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "origin     Lemma Category MorInfo1\n0    가나다순     NS02      ZNZ\n1     개인별     NS03      ZNZ\n2      개중     NS02      ZNZ\n3     갱스터     NS01      ZNZ\n4     검식관     NS02      ZNZ\n..    ...      ...      ...\n371    중장     NS02      ZNZ\n372   증후군     NS02      ZNE\n373   지상전     NS02      ZNZ\n374   지아이     NS01      ZNZ\n375   지은이     NS01      ZNE\n\n[376 rows x 3 columns]\ndata\n    Lemma Category MorInfo1 MorInfo2 MorInfo3 MorInfo4 MorInfo5\n0    종생부     NS01      ZNW                                    \n1     종언     NS02      ZNW                                    \n2    종이학     NS02      ZNW                                    \n3    주술적     NS02      ZNW                                    \n4    주의적     NS02      ZNW                                    \n5     주종     NS02      ZNW                                    \n6   주체사관     NS02      ZNW                                    \n7     주총     NS02      ZNW                                    \n8    주춧돌     NS03      ZNW                                    \n9    지상전     NS02      ZNW                                    \n10   지아이     NS01      ZNW                                    \n11   지은이     NS01      ZNW                                    \n12    가게     NS01      ZNW      LEO      SLB      HAL      MCO\n13    가격     NS02      ZNW      LEO      SLB      NAB         \n14    가결     NS03      ZNW      LEO      SLB      PHV         \nmerge_data\n     Lemma Category MorInfo1 MorInfo2 MorInfo3 MorInfo4 MorInfo5\n0      가게     NS01      ZNW      LEO      SLB      HAL      MCO\n1      가격     NS02      ZNW      LEO      SLB      NAB         \n2      가결     NS03      ZNW      LEO      SLB      PHV         \n3    가나다순     NS02      ZNZ                                    \n4     개인별     NS03      ZNZ                                    \n..    ...      ...      ...      ...      ...      ...      ...\n386   지상전     NS02      ZNW                                    \n387   지아이     NS01      ZNZ                                    \n388   지아이     NS01      ZNW                                    \n389   지은이     NS01      ZNW                                    \n390   지은이     NS01      ZNE                                    \n\n[391 rows x 7 columns]\nrules\n [['MorInfo', nan], ['ZNZ', 'ZNW'], ['ZNE', 'ZNW']]\n[['ZNZ', 'ZNW'], ['ZNE', 'ZNW']]\n['Lemma', 'Category', 'MorInfo1', 'MorInfo2', 'MorInfo3', 'MorInfo4', 'MorInfo5']\n종생부\nNS01\nZNW\n['Lemma', 'Category', 'MorInfo1', 'MorInfo2', 'MorInfo3', 'MorInfo4', 'MorInfo5']\n종언\nNS02\nZNW\n['Lemma', 'Category', 'MorInfo1', 'MorInfo2', 'MorInfo3', 'MorInfo4', 'MorInfo5']\n종이학\nNS02\nZNW\n['Lemma', 'Category', 'MorInfo1', 'MorInfo2', 'MorInfo3', 'MorInfo4', 'MorInfo5']\n주의적\nNS02\nZNW\n['Lemma', 'Category', 'MorInfo1', 'MorInfo2', 'MorInfo3', 'MorInfo4', 'MorInfo5']\n지상전\nNS02\nZNW\n['Lemma', 'Category', 'MorInfo1', 'MorInfo2', 'MorInfo3', 'MorInfo4', 'MorInfo5']\n지아이\nNS01\nZNW\n   Lemma Category MorInfo1 MorInfo2 MorInfo3 MorInfo4 MorInfo5\n0    종생부     NS01      ZNZ                                    \n1     종언     NS02      ZNZ                                    \n2    종이학     NS02      ZNZ                                    \n3    주술적     NS02      ZNZ                                    \n4    주의적     NS02      ZNZ                                    \n5   주체사관     NS02      ZNZ                                    \n6     주총     NS02      ZNZ                                    \n7    지상전     NS02      ZNZ                                    \n8    지아이     NS01      ZNZ                                    \n9     주종     NS02      ZNE                                    \n10   지은이     NS01      ZNE                                    \n    Lemma Category MorInfo1 MorInfo2 MorInfo3 MorInfo4 MorInfo5\n0      가게     NS01      ZNW      LEO      SLB      HAL      MCO\n1      가격     NS02      ZNW      LEO      SLB      NAB         \n2      가결     NS03      ZNW      LEO      SLB      PHV         \n3    가나다순     NS02      ZNZ                                    \n4     개인별     NS03      ZNZ                                    \n..    ...      ...      ...      ...      ...      ...      ...\n375    중장     NS02      ZNZ                                    \n376   증후군     NS02      ZNE                                    \n377   지상전     NS02      ZNZ                                    \n378   지아이     NS01      ZNZ                                    \n379   지은이     NS01      ZNE                                    \n\n[380 rows x 7 columns]\n"
    }
   ],
   "source": [
    "merge_fname=([r\"E:\\Develop\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge2.csv\", r\"E:\\Develop\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge3.csv\"], 'CSV Files(*.csv)')\n",
    "\n",
    "# def merge(self):\n",
    "\n",
    "# 들어오는 데이터를 병합할 변수\n",
    "merge_data = pd.read_csv (merge_fname[0][0], header=None, encoding='utf-8-sig')\n",
    "merge_data = column_name (merge_data)\n",
    "print(\"origin\", merge_data)\n",
    "data_files = merge_fname[0][1:]\n",
    "data_df_list = []\n",
    "for i in data_files:\n",
    "    temp_data = pd.read_csv (i, header=None, encoding='utf-8-sig')\n",
    "    temp_data = column_name (temp_data)\n",
    "    data_df_list.append (temp_data)\n",
    "# 두 번째부터는 들어오는 데이터를 data변수에 저장하고\n",
    "# 이전에 저장해둔 merge_data와 data를 concat으로 병합한 뒤\n",
    "# 두 데이터를 sort_values로 정렬을 시켜준다.\n",
    "for data in data_df_list:\n",
    "    print('data\\n', data)\n",
    "    merge_data = pd.concat ([merge_data, data], ignore_index=True)\n",
    "merge_data = merge_data.sort_values (by='Lemma')\n",
    "merge_data = merge_data.reset_index ()\n",
    "merge_data = merge_data.fillna ('')\n",
    "del merge_data['index']\n",
    "print(\"merge_data\\n\", merge_data)\n",
    "cnt = 1\n",
    "\n",
    "# 우선시 되는 데이터 : my_data, 지워져도 되는 데이터 del_data\n",
    "# gui상에서 .text()로 입력받는다.\n",
    "rule_data = pd.read_csv (r\"E:\\Develop\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Rules.csv\", header=None, encoding='utf-8-sig')\n",
    "rules = []\n",
    "for rule_cnt in range (len (rule_data)):\n",
    "    rules.append (rule_data.loc[rule_cnt].to_list ())\n",
    "print(\"rules\\n\", rules)\n",
    "# 사용자가 입력할 col_name.\n",
    "# gui상에서 .text()로 입력받는다.\n",
    "col_data = rules[0][0]\n",
    "\n",
    "del rules[0]\n",
    "print(rules)\n",
    "del_row_list = []\n",
    "for rule in rules:\n",
    "    my_data = rule[0]\n",
    "    del_data = rule[1]\n",
    "    for i in range (0, len (merge_data) - 1):\n",
    "        for j in range (i + 1, i + cnt + 1):\n",
    "            # first에는 i번째 단어를 음절별로 나누어서 저장하고\n",
    "            # second에는 j번째(i다음 단어)를 음절로 나누어서 저장한다.\n",
    "            first = merge_data.loc[i, 'Lemma']\n",
    "            second = merge_data.loc[j, 'Lemma']\n",
    "            first_len = len (merge_data.loc[i, 'Lemma'])\n",
    "            second_len = len (merge_data.loc[j, 'Lemma'])\n",
    "            if first_len != second_len:\n",
    "                break\n",
    "                # 만약 단어의 앞글자가 같다면 아래 코드를 실행한다.\n",
    "            else:\n",
    "                # 앞글자는 같지만 단어가 다르면 for문을 종료한다.\n",
    "                if first != second:\n",
    "                    break\n",
    "\n",
    "                # 앞글자가 같고 단어까지 같으면 입력 받은 mydata가 i번째에 있는지 아님 j(i+1)번째 있는지 확인한다.\n",
    "                else:\n",
    "                    for col_nms in merge_data.columns.tolist():\n",
    "                        if col_data in col_nms:\n",
    "                            # stem_data가 유지해야하는 data일때\n",
    "                            if my_data == merge_data.loc[i, col_nms] and del_data == merge_data.loc[j, col_nms]:\n",
    "                                stem_data1 = merge_data.iloc[i].values.tolist ()[2:]\n",
    "                                follow_data1 = merge_data.iloc[j].values.tolist ()[2:]\n",
    "                                for data in stem_data1:\n",
    "                                    if data not in follow_data1:\n",
    "                                        col = check_info (data)\n",
    "                                        col_nme = merge_data.columns.tolist()\n",
    "                                        print(col_nme)\n",
    "                                        for mer_col in col_nme:\n",
    "                                            print(merge_data.loc[j, mer_col])\n",
    "                                            if col in mer_col and merge_data.loc[j, mer_col] == del_data:\n",
    "                                                merge_data.loc[j, mer_col] = data\n",
    "                                                break\n",
    "                                del_row_list.append (j)\n",
    "\n",
    "                            elif my_data == merge_data.loc[j, col_nms] and del_data == merge_data.loc[i, col_nms]:\n",
    "                                stem_data2 = merge_data.iloc[j].values.tolist ()[2:]\n",
    "                                follow_data2 = merge_data.iloc[i].values.tolist ()[2:]\n",
    "                                for data in stem_data2:\n",
    "                                    if data not in follow_data2:\n",
    "                                        col = check_info (data)\n",
    "                                        #print(\"col\", col)\n",
    "                                        col_nme = merge_data.columns\n",
    "                                        #print(col_nme)\n",
    "                                        for mer_col in col_nme:\n",
    "                                            if col in mer_col and merge_data.loc[i, mer_col] == del_data:\n",
    "                                                merge_data.loc[i, mer_col] = data\n",
    "                                                break\n",
    "                                del_row_list.append (i)\n",
    "                            else:\n",
    "                                pass\n",
    "del_temp = []\n",
    "for i in del_row_list:\n",
    "    del_temp.append (merge_data.iloc[i].tolist ())\n",
    "del_df = pd.DataFrame (del_temp)\n",
    "if len(del_df) != 0:\n",
    "    del_df = column_name (del_df)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(del_df)\n",
    "\n",
    "merge_data = merge_data.drop (del_row_list, 0)\n",
    "merge_data = merge_data.reset_index ()\n",
    "del merge_data[\"index\"]\n",
    "\n",
    "print(merge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitbaseconda7ccc1197ea424c04aa8e970980241a68",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}