{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def column_name(df):\n",
    "    # 첫 행 살리기\n",
    "    first = list (df.columns)\n",
    "    if first[0] == 0:\n",
    "        pass\n",
    "    else:\n",
    "        df.loc[0] = first\n",
    "        for val in first:\n",
    "            if 'Unnamed' in val:\n",
    "                x = first.index (val)\n",
    "                first[x] = np.nan\n",
    "        df.loc[0] = first\n",
    "    df = df.fillna ('')\n",
    "    sem_rgx = re.compile (r'[Q][A-Z]{3}')  # semantic tagset\n",
    "    syn_rgx = re.compile (r'[Y][A-Z]{3}')  # syntactic tagset\n",
    "    dom_rgx = re.compile (r'[X]{1}[ABCDEFGHIJKLMNOPQRSTUVWYZ]{3}')  # domain tagset\n",
    "    ent_rgx = re.compile (r'[X]{2}[A-Z]{2}')  # entity tagset\n",
    "    mor_rgx = re.compile (r'[A-Z]{3}')  # morph tagset\n",
    "\n",
    "    # 컬럼의 총 개수를 l에 저장한다.\n",
    "    # 컬럼의 개수 만큼 lemma와 category뒤에 lemma와 category개수인 2를 뺀만큼\n",
    "    # ''를 추가해 주어 해당 컬럼 개수 만큼의 리스트 col_nme을 만들어 준다.\n",
    "    l = len (df.columns)\n",
    "    col_nme = ['Lemma', 'Category']\n",
    "    for i in range (l - 2):\n",
    "        col_nme.append ('')\n",
    "    # sem =>SemInfo 뒤에 붙을 숫자\n",
    "    # syn =>SynInfo 뒤에 붙을 숫자\n",
    "    # dom =>DomInfo 뒤에 붙을 숫자\n",
    "    # ent =>EntInfo 뒤에 붙을 숫자\n",
    "    # mor =>MorInfo 뒤에 붙을 숫자\n",
    "    sem = 1\n",
    "    syn = 1\n",
    "    dom = 1\n",
    "    ent = 1\n",
    "    mor = 1\n",
    "\n",
    "    # x를 컬럼의 개수 만큼의 숫자로 지정해 준다.\n",
    "    # col_val은 해당 df의 열을 리스트화 시켜준 것이다.\n",
    "    for x in range (0, l):\n",
    "        col_val = df.iloc[:, x].tolist ()\n",
    "        # cnt가 0이면 일치하는 값을 못 찾았다는 의미로 해석(ex 모두 빈칸인 열을 만났을 때)\n",
    "        # 밑에서 cnt == 0 일때 앞에 정보를 보고 빈칸의 정보를 수정할 때 사용한다.\n",
    "        cnt = 0\n",
    "        # k로 col_val의 리스트 요소들을 하나씩 지정해주면서\n",
    "        # k가 sem_rgx, syn_rgx, dom_rgx, ent_rgx, mor_rgx에 해당되면\n",
    "        # 컬럼에 일치하는 값이 있었다는 의미로 cnt를 1 증가시켜 주고\n",
    "        # Info뒤에 붙을 숫자를 1씩 증가시켜 주고\n",
    "        # 비효율적인 탐색을 막기 위해 바로 break시켜준다.\n",
    "        for k in col_val:\n",
    "            if sem_rgx.match (k):\n",
    "                col_nme[x] = 'SemInfo' + str (sem)\n",
    "                sem += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif syn_rgx.match (k):\n",
    "                col_nme[x] = 'SynInfo' + str (syn)\n",
    "                syn += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif dom_rgx.match (k):\n",
    "                col_nme[x] = 'DomInfo' + str (dom)\n",
    "                dom += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif ent_rgx.match (k):\n",
    "                col_nme[x] = 'EntInfo' + str (ent)\n",
    "                ent += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "            elif mor_rgx.match (k):\n",
    "                col_nme[x] = 'MorInfo' + str (mor)\n",
    "                mor += 1\n",
    "                cnt += 1\n",
    "                break\n",
    "\n",
    "        # 만약 위에서 일치하는 값을 못찾았을 때(ex 모두 빈칸인 열이었을 때)\n",
    "        # cnt는 0이므로 앞에 col_nme의 정보를 보고\n",
    "        # 해당 정보와 일치하는 정보의 Info숫자를 증가시켜준 값을 해당 리스트 위치에 저장해준다.\n",
    "        if cnt == 0:\n",
    "            if 'Sem' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'SemInfo' + str (sem)\n",
    "                sem += 1\n",
    "\n",
    "            elif 'Syn' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'SynInfo' + str (syn)\n",
    "                syn += 1\n",
    "\n",
    "            elif 'Dom' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'DomInfo' + str (dom)\n",
    "                dom += 1\n",
    "\n",
    "            elif 'Ent' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'EntInfo' + str (ent)\n",
    "                ent += 1\n",
    "\n",
    "            elif 'Mor' in col_nme[x - 1]:\n",
    "                col_nme[x] = 'MorInfo' + str (mor)\n",
    "                mor += 1\n",
    "\n",
    "    df.columns = col_nme\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_info(word):\n",
    "    sem_rgx = re.compile (r'[Q][A-Z]{3}')  # semantic tagset\n",
    "    syn_rgx = re.compile (r'[Y][A-Z]{3}')  # syntactic tagset\n",
    "    dom_rgx = re.compile (r'[X]{1}[ABCDEFGHIJKLMNOPQRSTUVWYZ]{3}')  # domain tagset\n",
    "    ent_rgx = re.compile (r'[X]{2}[A-Z]{2}')  # entity tagset\n",
    "    mor_rgx = re.compile (r'[A-Z]{3}')  # morph tagset\n",
    "\n",
    "    if sem_rgx.match (word):\n",
    "        return 'SenInfo'\n",
    "    elif syn_rgx.match (word):\n",
    "        return 'SynInfo'\n",
    "    elif dom_rgx.match (word):\n",
    "        return 'DomInfo'\n",
    "    elif ent_rgx.match (word):\n",
    "        return 'EntInfo'\n",
    "    elif mor_rgx.match (word):\n",
    "        return 'MorInfo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "origin     Lemma Category MorInfo1\n0    가나다순     NS02      ZNZ\n1     개인별     NS03      ZNZ\n2      개중     NS02      ZNZ\n3     갱스터     NS01      ZNZ\n4     검식관     NS02      ZNZ\n..    ...      ...      ...\n371    중장     NS02      ZNZ\n372   증후군     NS02      ZNE\n373   지상전     NS02      ZNZ\n374   지아이     NS01      ZNZ\n375   지은이     NS01      ZNE\n\n[376 rows x 3 columns]\ndata\n    Lemma Category MorInfo1 MorInfo2 MorInfo3 MorInfo4 MorInfo5\n0    종생부     NS01      ZNW                                    \n1     종언     NS02      ZNW                                    \n2    종이학     NS02      ZNW                                    \n3    주술적     NS02      ZNW                                    \n4    주의적     NS02      ZNW                                    \n5     주종     NS02      ZNW                                    \n6   주체사관     NS02      ZNW                                    \n7     주총     NS02      ZNW                                    \n8    주춧돌     NS03      ZNW                                    \n9    지상전     NS02      ZNW                                    \n10   지아이     NS01      ZNW                                    \n11   지은이     NS01      ZNW                                    \n12    가게     NS01      ZNW      LEO      SLB      HAL      MCO\n13    가격     NS02      ZNW      LEO      SLB      NAB         \n14    가결     NS03      ZNW      LEO      SLB      PHV         \nmerge_data\n     Lemma Category MorInfo1 MorInfo2 MorInfo3 MorInfo4 MorInfo5\n0      가게     NS01      ZNW      LEO      SLB      HAL      MCO\n1      가격     NS02      ZNW      LEO      SLB      NAB         \n2      가결     NS03      ZNW      LEO      SLB      PHV         \n3    가나다순     NS02      ZNZ                                    \n4     개인별     NS03      ZNZ                                    \n..    ...      ...      ...      ...      ...      ...      ...\n386   지상전     NS02      ZNW                                    \n387   지아이     NS01      ZNZ                                    \n388   지아이     NS01      ZNW                                    \n389   지은이     NS01      ZNW                                    \n390   지은이     NS01      ZNE                                    \n\n[391 rows x 7 columns]\nrules\n [['MorInfo', nan], ['ZNZ', 'ZNW'], ['ZNE', 'ZNW']]\n[['ZNZ', 'ZNW'], ['ZNE', 'ZNW']]\n['ZNZ', '', '', '', '']\n['ZNZ', '', '', '', '']\n['ZNZ', '', '', '', '']\n['ZNZ', '', '', '', '']\n['ZNZ', '', '', '', '']\n['ZNZ', '', '', '', '']\n   Lemma Category MorInfo1 MorInfo2 MorInfo3 MorInfo4 MorInfo5\n0    종생부     NS01      ZNZ                                    \n1     종언     NS02      ZNZ                                    \n2    종이학     NS02      ZNZ                                    \n3    주술적     NS02      ZNZ                                    \n4    주의적     NS02      ZNZ                                    \n5   주체사관     NS02      ZNZ                                    \n6     주총     NS02      ZNZ                                    \n7    지상전     NS02      ZNZ                                    \n8    지아이     NS01      ZNZ                                    \n9     주종     NS02      ZNE                                    \n10   지은이     NS01      ZNE                                    \n    Lemma Category MorInfo1 MorInfo2 MorInfo3 MorInfo4 MorInfo5\n0      가게     NS01      ZNW      LEO      SLB      HAL      MCO\n1      가격     NS02      ZNW      LEO      SLB      NAB         \n2      가결     NS03      ZNW      LEO      SLB      PHV         \n3    가나다순     NS02      ZNZ                                    \n4     개인별     NS03      ZNZ                                    \n..    ...      ...      ...      ...      ...      ...      ...\n375    중장     NS02      ZNZ                                    \n376   증후군     NS02      ZNE                                    \n377   지상전     NS02      ZNZ                                    \n378   지아이     NS01      ZNZ                                    \n379   지은이     NS01      ZNE                                    \n\n[380 rows x 7 columns]\n"
    }
   ],
   "source": [
    "merge_fname=([r\"E:\\Develop\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge2.csv\", r\"E:\\Develop\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Merge3.csv\"], 'CSV Files(*.csv)')\n",
    "\n",
    "# def merge(self):\n",
    "\n",
    "# 들어오는 데이터를 병합할 변수\n",
    "merge_data = pd.read_csv (merge_fname[0][0], header=None, encoding='utf-8-sig')\n",
    "merge_data = column_name (merge_data)\n",
    "print(\"origin\", merge_data)\n",
    "data_files = merge_fname[0][1:]\n",
    "data_df_list = []\n",
    "for i in data_files:\n",
    "    temp_data = pd.read_csv (i, header=None, encoding='utf-8-sig')\n",
    "    temp_data = column_name (temp_data)\n",
    "    data_df_list.append (temp_data)\n",
    "# 두 번째부터는 들어오는 데이터를 data변수에 저장하고\n",
    "# 이전에 저장해둔 merge_data와 data를 concat으로 병합한 뒤\n",
    "# 두 데이터를 sort_values로 정렬을 시켜준다.\n",
    "for data in data_df_list:\n",
    "    print('data\\n', data)\n",
    "    merge_data = pd.concat ([merge_data, data], ignore_index=True)\n",
    "merge_data = merge_data.sort_values (by='Lemma')\n",
    "merge_data = merge_data.reset_index ()\n",
    "merge_data = merge_data.fillna ('')\n",
    "del merge_data['index']\n",
    "print(\"merge_data\\n\", merge_data)\n",
    "cnt = 1\n",
    "\n",
    "# 우선시 되는 데이터 : my_data, 지워져도 되는 데이터 del_data\n",
    "# gui상에서 .text()로 입력받는다.\n",
    "rule_data = pd.read_csv (r\"E:\\Develop\\python\\NLP\\DecoLexO\\DecoLexO\\example\\Rules.csv\", header=None, encoding='utf-8-sig')\n",
    "rules = []\n",
    "for rule_cnt in range (len (rule_data)):\n",
    "    rules.append (rule_data.loc[rule_cnt].to_list ())\n",
    "print(\"rules\\n\", rules)\n",
    "# 사용자가 입력할 col_name.\n",
    "# gui상에서 .text()로 입력받는다.\n",
    "col_data = rules[0][0]\n",
    "\n",
    "del rules[0]\n",
    "print(rules)\n",
    "del_row_list = []\n",
    "for rule in rules:\n",
    "    my_data = rule[0]\n",
    "    del_data = rule[1]\n",
    "    for i in range (0, len (merge_data) - 1):\n",
    "        for j in range (i + 1, i + cnt + 1):\n",
    "            # first에는 i번째 단어를 음절별로 나누어서 저장하고\n",
    "            # second에는 j번째(i다음 단어)를 음절로 나누어서 저장한다.\n",
    "            first = merge_data.loc[i, 'Lemma']\n",
    "            second = merge_data.loc[j, 'Lemma']\n",
    "            first_len = len (merge_data.loc[i, 'Lemma'])\n",
    "            second_len = len (merge_data.loc[j, 'Lemma'])\n",
    "            if first_len != second_len:\n",
    "                break\n",
    "                # 만약 단어의 앞글자가 같다면 아래 코드를 실행한다.\n",
    "            else:\n",
    "                # 앞글자는 같지만 단어가 다르면 for문을 종료한다.\n",
    "                if first != second:\n",
    "                    break\n",
    "\n",
    "                # 앞글자가 같고 단어까지 같으면 입력 받은 mydata가 i번째에 있는지 아님 j(i+1)번째 있는지 확인한다.\n",
    "                else:\n",
    "                    for col_nms in merge_data.columns.tolist():\n",
    "                        if col_data in col_nms:\n",
    "                            # stem_data가 유지해야하는 data일때\n",
    "                            if my_data == merge_data.loc[i, col_nms] and del_data == merge_data.loc[j, col_nms]:\n",
    "                                stem_data1 = merge_data.iloc[i].values.tolist ()[2:]\n",
    "                                follow_data1 = merge_data.iloc[j].values.tolist ()[2:]\n",
    "                                print(stem_data1)\n",
    "                                for data in stem_data1:\n",
    "                                    if data not in follow_data1:\n",
    "                                        col = check_info (data)\n",
    "                                        col_nme = merge_data.columns.tolist()\n",
    "                                        for mer_col in col_nme:\n",
    "                                            if col in mer_col and merge_data.loc[j, mer_col] == del_data:\n",
    "                                                merge_data.loc[j, mer_col] = data\n",
    "                                                break\n",
    "                                del_row_list.append (j)\n",
    "\n",
    "                            elif my_data == merge_data.loc[j, col_nms] and del_data == merge_data.loc[i, col_nms]:\n",
    "                                stem_data2 = merge_data.iloc[j].values.tolist ()[2:]\n",
    "                                follow_data2 = merge_data.iloc[i].values.tolist ()[2:]\n",
    "                                for data in stem_data2:\n",
    "                                    if data not in follow_data2:\n",
    "                                        col = check_info (data)\n",
    "                                        #print(\"col\", col)\n",
    "                                        col_nme = merge_data.columns\n",
    "                                        #print(col_nme)\n",
    "                                        for mer_col in col_nme:\n",
    "                                            if col in mer_col and merge_data.loc[i, mer_col] == del_data:\n",
    "                                                merge_data.loc[i, mer_col] = data\n",
    "                                                break\n",
    "                                del_row_list.append (i)\n",
    "                            else:\n",
    "                                pass\n",
    "del_temp = []\n",
    "for i in del_row_list:\n",
    "    del_temp.append (merge_data.iloc[i].tolist ())\n",
    "del_df = pd.DataFrame (del_temp)\n",
    "if len(del_df) != 0:\n",
    "    del_df = column_name (del_df)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(del_df)\n",
    "\n",
    "merge_data = merge_data.drop (del_row_list, 0)\n",
    "merge_data = merge_data.reset_index ()\n",
    "del merge_data[\"index\"]\n",
    "\n",
    "print(merge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1593445199427",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}